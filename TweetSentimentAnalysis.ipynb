{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAmXyIqoFqE8"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "consumer_key = Con_key\n",
        "consumer_secret = Con_secret\n",
        "access_token = Access_token\n",
        "access_token_secret = Token_secret\n",
        "\n",
        "def authenticate_twitter():\n",
        "    try:\n",
        "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "        auth.set_access_token(access_token, access_token_secret)\n",
        "        api = tweepy.API(auth)\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        print(\"Error during authentication:\", e)\n",
        "        return None\n",
        "\n",
        "def fetch_tweets(api, query, count=100):\n",
        "    try:\n",
        "        tweets = []\n",
        "        for tweet in tweepy.Cursor(api.search_tweets, q=query, lang='en', tweet_mode='extended').items(count):\n",
        "            tweets.append(tweet.full_text)\n",
        "        return tweets\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching tweets:\", e)\n",
        "        return []\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "    tweet = re.sub(r'\\@\\w+|\\#', '', tweet)\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tokens = word_tokenize(tweet)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def analyze_sentiment(tweet):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(tweet)\n",
        "    if scores['compound'] >= 0.05:\n",
        "        return 'Positive', scores['compound']\n",
        "    elif scores['compound'] <= -0.05:\n",
        "        return 'Negative', scores['compound']\n",
        "    else:\n",
        "        return 'Neutral', scores['compound']\n",
        "\n",
        "def main():\n",
        "    api = authenticate_twitter()\n",
        "    if not api:\n",
        "        return\n",
        "\n",
        "    query = input(\"Enter a search term to analyze tweets: \")\n",
        "    num_tweets = int(input(\"How many tweets to analyze? (max 100): \"))\n",
        "\n",
        "    raw_tweets = fetch_tweets(api, query, min(num_tweets, 100))\n",
        "    if not raw_tweets:\n",
        "        print(\"No tweets found or error occurred.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "    for tweet in raw_tweets:\n",
        "        cleaned = clean_tweet(tweet)\n",
        "        processed = preprocess_tweet(cleaned)\n",
        "        sentiment, score = analyze_sentiment(processed)\n",
        "        results.append({\n",
        "            'Original Tweet': tweet,\n",
        "            'Cleaned Tweet': cleaned,\n",
        "            'Processed Text': processed,\n",
        "            'Sentiment': sentiment,\n",
        "            'Sentiment Score': score\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"\\nSentiment Analysis Results:\")\n",
        "    print(df[['Original Tweet', 'Sentiment', 'Sentiment Score']].head())\n",
        "\n",
        "    print(\"\\nSentiment Distribution:\")\n",
        "    print(df['Sentiment'].value_counts())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}